{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset-mei.csv', delimiter=';')\n",
    "\n",
    "with open('stopwords.json', 'r') as file:\n",
    "    stopwords_arr = json.load(file)\n",
    "df_slang = pd.read_csv('kamus.csv', delimiter=';')\n",
    "df_lexicon = pd.read_csv('lexicon.csv', delimiter=';')\n",
    "\n",
    "stemmer = StemmerFactory().create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = text.replace('-ness', '')\n",
    "    text = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", text)\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = re.sub(r'/n', ' ', text)\n",
    "    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    text = re.sub(r'(?<!\\bunnes)(\\w)(\\1+)(?=\\s|[\\.,!])', r'\\1', text)\n",
    "    text = text.strip(' ')\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    text = text.lower()  \n",
    "    return text\n",
    "\n",
    "def replace_word(text):\n",
    "    elongated_words = re.findall(r'\\b\\w*(?:(\\w)\\1{2,})\\w*\\b', text)\n",
    "    for word in elongated_words:\n",
    "        replacement = word[0]\n",
    "        text = re.sub(r'\\b' + re.escape(word) + r'\\b', replacement, text)\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "def translate_slang(tokens):\n",
    "    translated_tokens = []\n",
    "    slang_dict = df_slang.set_index('singkatan').to_dict()['kata']\n",
    "    for word in tokens:\n",
    "        translated_tokens.append(slang_dict.get(word, word))\n",
    "    return translated_tokens\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, list):  # Check if text is a list\n",
    "        clean_words = []\n",
    "        for sentence in text:  # Iterate through sentences in the list\n",
    "            words = sentence.split()  # Split each sentence into words\n",
    "            clean_sentence = [word for word in words if word.lower() not in stopwords_arr]\n",
    "            clean_words.extend(clean_sentence)  # Add cleaned sentence words\n",
    "        return clean_words\n",
    "    else:\n",
    "        words = text.split()  # Handle single string case\n",
    "        clean_words = [word for word in words if word.lower() not in stopwords_arr]\n",
    "        return clean_words\n",
    "    \n",
    "def stemming(tokens):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "def remove_duplicates(tokens):\n",
    "    unique_tokens = []\n",
    "    [unique_tokens.append(token) for token in tokens if token not in unique_tokens]\n",
    "    return unique_tokens\n",
    "\n",
    "def calculate_score(tokens, df_lexicon):\n",
    "    score = 0\n",
    "    \n",
    "    # Hitung skor berdasarkan leksikon\n",
    "    for token in tokens:\n",
    "        if token in df_lexicon['word'].values:\n",
    "            score += df_lexicon[df_lexicon['word'] == token]['weight'].values[0]\n",
    "    return score \n",
    "\n",
    "def sentiment(score):\n",
    "    # Menentukan polaritas berdasarkan skor\n",
    "    if score > 0:\n",
    "        sentiment = 'positive'\n",
    "    elif score < 0:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    \n",
    "    return sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['full_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Kolom yang akan dihapus\n",
    "columns_to_drop = [\n",
    "    'conversation_id_str', 'created_at', 'favorite_count', 'id_str', \n",
    "    'image_url', 'in_reply_to_screen_name', 'lang', 'location', \n",
    "    'quote_count', 'reply_count', 'retweet_count', 'tweet_url', \n",
    "    'user_id_str', 'username'\n",
    "]\n",
    "\n",
    "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.copy()\n",
    "# # data['clean_text'] = data['full_text'].apply(remove_duplicates)\n",
    "# data = data.drop_duplicates(subset='full_text')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>cw horor lihatlah apa yg kutemukan di unnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>kantin rektorat unnes malam hari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>the most delicioso kebab in unnes the one and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>belum buka nder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>qris bisa nder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>mowning ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  \n",
       "0     my dream university mixed feeling banget ke un...  \n",
       "1     syp utbk nya di gedung arsip unnes cung aku ga...  \n",
       "2           cw horor lihatlah apa yg kutemukan di unnes  \n",
       "3                      kantin rektorat unnes malam hari  \n",
       "4     the most delicioso kebab in unnes the one and ...  \n",
       "...                                                 ...  \n",
       "4601      aku bingung harus daftar kedinasan atau engga  \n",
       "4602                                    belum buka nder  \n",
       "4603                                     qris bisa nder  \n",
       "4604                                                     \n",
       "4605                                         mowning ca  \n",
       "\n",
       "[4606 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'] = data['full_text'].apply(cleaning)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>cw horor lihatlah apa yg kutemukan di unnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>kantin rektorat unnes malam hari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>the most delicioso kebab in unnes the one and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>belum buka nder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>qris bisa nder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>mowning ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  \n",
       "0     my dream university mixed feeling banget ke un...  \n",
       "1     syp utbk nya di gedung arsip unnes cung aku ga...  \n",
       "2           cw horor lihatlah apa yg kutemukan di unnes  \n",
       "3                      kantin rektorat unnes malam hari  \n",
       "4     the most delicioso kebab in unnes the one and ...  \n",
       "...                                                 ...  \n",
       "4601      aku bingung harus daftar kedinasan atau engga  \n",
       "4602                                    belum buka nder  \n",
       "4603                                     qris bisa nder  \n",
       "4604                                                     \n",
       "4605                                         mowning ca  \n",
       "\n",
       "[4606 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'] = data['clean_text'].apply(replace_word)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>[my, dream, university, mixed, feeling, banget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>[syp, utbk, nya, di, gedung, arsip, unnes, cun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>[cw, horor, lihatlah, apa, yg, kutemukan, di, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>[kantin, rektorat, unnes, malam, hari]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>[the, most, delicioso, kebab, in, unnes, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>[aku, bingung, harus, daftar, kedinasan, atau,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>[belum, buka, nder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>[qris, bisa, nder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>[mowning, ca]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  \n",
       "0     [my, dream, university, mixed, feeling, banget...  \n",
       "1     [syp, utbk, nya, di, gedung, arsip, unnes, cun...  \n",
       "2     [cw, horor, lihatlah, apa, yg, kutemukan, di, ...  \n",
       "3                [kantin, rektorat, unnes, malam, hari]  \n",
       "4     [the, most, delicioso, kebab, in, unnes, the, ...  \n",
       "...                                                 ...  \n",
       "4601  [aku, bingung, harus, daftar, kedinasan, atau,...  \n",
       "4602                                [belum, buka, nder]  \n",
       "4603                                 [qris, bisa, nder]  \n",
       "4604                                                 []  \n",
       "4605                                      [mowning, ca]  \n",
       "\n",
       "[4606 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'] = data['clean_text'].apply(tokenize)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>[my, dream, university, mixed, feeling, sekali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>[siapa, utbk, nya, di, gedung, arsip, unnes, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>[cewek , horor, lihatlah, apa, yang , kutemuka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>[kantin, rektorat, unnes, malam, hari]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>[the, most, delicioso, kebab, in, unnes, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>[saya, bingung, harus, daftar, kedinasan, atau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>[belum, buka, nder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>[qris, bisa, nder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>[mowning, ca]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  \n",
       "0     [my, dream, university, mixed, feeling, sekali...  \n",
       "1     [siapa, utbk, nya, di, gedung, arsip, unnes, c...  \n",
       "2     [cewek , horor, lihatlah, apa, yang , kutemuka...  \n",
       "3                [kantin, rektorat, unnes, malam, hari]  \n",
       "4     [the, most, delicioso, kebab, in, unnes, the, ...  \n",
       "...                                                 ...  \n",
       "4601  [saya, bingung, harus, daftar, kedinasan, atau...  \n",
       "4602                                [belum, buka, nder]  \n",
       "4603                                 [qris, bisa, nder]  \n",
       "4604                                                 []  \n",
       "4605                                      [mowning, ca]  \n",
       "\n",
       "[4606 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'] = data['clean_text'].apply(translate_slang)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>[my, dream, university, mixed, feeling, pas, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>[utbk, gedung, arsip, cung, teman]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>[cewek, horor, lihatlah, kutemukan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>[kantin, rektorat, malam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>[the, most, delicioso, kebab, in, the, one, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>[bingung, daftar, kedinasan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>[buka]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>[qris]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>[mowning, ca]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  \n",
       "0     [my, dream, university, mixed, feeling, pas, s...  \n",
       "1                    [utbk, gedung, arsip, cung, teman]  \n",
       "2                   [cewek, horor, lihatlah, kutemukan]  \n",
       "3                             [kantin, rektorat, malam]  \n",
       "4     [the, most, delicioso, kebab, in, the, one, an...  \n",
       "...                                                 ...  \n",
       "4601                       [bingung, daftar, kedinasan]  \n",
       "4602                                             [buka]  \n",
       "4603                                             [qris]  \n",
       "4604                                                 []  \n",
       "4605                                      [mowning, ca]  \n",
       "\n",
       "[4606 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'] = data['clean_text'].apply(lambda x: remove_stopwords(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>[my, dream, university, mixed, feeling, pas, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>[utbk, gedung, arsip, cung, teman]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>[cewek, horor, lihat, temu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>[kantin, rektorat, malam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>[the, most, delicioso, kebab, in, the, one, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>[bingung, daftar, dinas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>[buka]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>[qris]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>[mowning, ca]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  \n",
       "0     [my, dream, university, mixed, feeling, pas, s...  \n",
       "1                    [utbk, gedung, arsip, cung, teman]  \n",
       "2                           [cewek, horor, lihat, temu]  \n",
       "3                             [kantin, rektorat, malam]  \n",
       "4     [the, most, delicioso, kebab, in, the, one, an...  \n",
       "...                                                 ...  \n",
       "4601                           [bingung, daftar, dinas]  \n",
       "4602                                             [buka]  \n",
       "4603                                             [qris]  \n",
       "4604                                                 []  \n",
       "4605                                      [mowning, ca]  \n",
       "\n",
       "[4606 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'] = data['clean_text'].apply(stemming)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>[my, dream, university, mixed, feeling, pas, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>[utbk, gedung, arsip, cung, teman]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>[cewek, horor, lihat, temu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>[kantin, rektorat, malam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>[the, most, delicioso, kebab, in, one, and, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>[bingung, daftar, dinas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>[buka]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>[qris]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>[mowning, ca]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  \n",
       "0     [my, dream, university, mixed, feeling, pas, s...  \n",
       "1                    [utbk, gedung, arsip, cung, teman]  \n",
       "2                           [cewek, horor, lihat, temu]  \n",
       "3                             [kantin, rektorat, malam]  \n",
       "4     [the, most, delicioso, kebab, in, one, and, on...  \n",
       "...                                                 ...  \n",
       "4601                           [bingung, daftar, dinas]  \n",
       "4602                                             [buka]  \n",
       "4603                                             [qris]  \n",
       "4604                                                 []  \n",
       "4605                                      [mowning, ca]  \n",
       "\n",
       "[4606 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'] = data['clean_text'].apply(remove_duplicates)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>[my, dream, university, mixed, feeling, pas, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>[utbk, gedung, arsip, cung, teman]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>[cewek, horor, lihat, temu]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>[kantin, rektorat, malam]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>[the, most, delicioso, kebab, in, one, and, on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>[bingung, daftar, dinas]</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>[buka]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>[qris]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>[mowning, ca]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  score  \n",
       "0     [my, dream, university, mixed, feeling, pas, s...      1  \n",
       "1                    [utbk, gedung, arsip, cung, teman]      0  \n",
       "2                           [cewek, horor, lihat, temu]     -3  \n",
       "3                             [kantin, rektorat, malam]      0  \n",
       "4     [the, most, delicioso, kebab, in, one, and, on...      1  \n",
       "...                                                 ...    ...  \n",
       "4601                           [bingung, daftar, dinas]     -2  \n",
       "4602                                             [buka]      0  \n",
       "4603                                             [qris]      0  \n",
       "4604                                                 []      0  \n",
       "4605                                      [mowning, ca]      0  \n",
       "\n",
       "[4606 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['score'] = data['clean_text'].apply(lambda x: calculate_score(x, df_lexicon))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>score</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>[my, dream, university, mixed, feeling, pas, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>[utbk, gedung, arsip, cung, teman]</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>[cewek, horor, lihat, temu]</td>\n",
       "      <td>-3</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>[kantin, rektorat, malam]</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>[the, most, delicioso, kebab, in, one, and, on...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>[bingung, daftar, dinas]</td>\n",
       "      <td>-2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>[buka]</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>[qris]</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>[mowning, ca]</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  score  sentimen  \n",
       "0     [my, dream, university, mixed, feeling, pas, s...      1  positive  \n",
       "1                    [utbk, gedung, arsip, cung, teman]      0   neutral  \n",
       "2                           [cewek, horor, lihat, temu]     -3  negative  \n",
       "3                             [kantin, rektorat, malam]      0   neutral  \n",
       "4     [the, most, delicioso, kebab, in, one, and, on...      1  positive  \n",
       "...                                                 ...    ...       ...  \n",
       "4601                           [bingung, daftar, dinas]     -2  negative  \n",
       "4602                                             [buka]      0   neutral  \n",
       "4603                                             [qris]      0   neutral  \n",
       "4604                                                 []      0   neutral  \n",
       "4605                                      [mowning, ca]      0   neutral  \n",
       "\n",
       "[4606 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentimen'] = data['score'].apply(sentiment)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentimen\n",
      "neutral     2370\n",
      "positive    1239\n",
      "negative     997\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "jumlah_sentimen = data['sentimen'].value_counts()\n",
    "\n",
    "print(jumlah_sentimen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = data[\"sentimen\"].value_counts()  \n",
    "desired_order = ['positive', 'neutral', 'negative']\n",
    "ordered_counts = counts.reindex(desired_order, fill_value=0)\n",
    "colors = ['red', 'blue', 'green'] \n",
    "plt.bar(ordered_counts.index, ordered_counts.values, color=colors)  \n",
    "\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['clean_text'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>score</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my dream university mixed feeling banget ke un...</td>\n",
       "      <td>my dream university mixed feeling pas selesai ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syp utbk nya di gedung arsip unnes cung aku ga...</td>\n",
       "      <td>utbk gedung arsip cung teman</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW//HOROR lihatlah apa yg kutemukan di unnes h...</td>\n",
       "      <td>cewek horor lihat temu</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kantin rektorat unnes malam hari https://t.co/...</td>\n",
       "      <td>kantin rektorat malam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most delicioso kebab in Unnes the one and ...</td>\n",
       "      <td>the most delicioso kebab in one and only gaza</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>aku bingung harus daftar kedinasan atau engga....</td>\n",
       "      <td>bingung daftar dinas</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>@unnesmenfess Belum buka nder</td>\n",
       "      <td>buka</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>@unnesmenfess Qris bisa nder</td>\n",
       "      <td>qris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>https://t.co/05wpAe4Zpm</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>@piyoby_ mowningg ca</td>\n",
       "      <td>mowning ca</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4606 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     my dream university mixed feeling banget ke un...   \n",
       "1     Syp utbk nya di gedung arsip unnes cung aku ga...   \n",
       "2     CW//HOROR lihatlah apa yg kutemukan di unnes h...   \n",
       "3     kantin rektorat unnes malam hari https://t.co/...   \n",
       "4     The most delicioso kebab in Unnes the one and ...   \n",
       "...                                                 ...   \n",
       "4601  aku bingung harus daftar kedinasan atau engga....   \n",
       "4602                      @unnesmenfess Belum buka nder   \n",
       "4603                       @unnesmenfess Qris bisa nder   \n",
       "4604                            https://t.co/05wpAe4Zpm   \n",
       "4605                               @piyoby_ mowningg ca   \n",
       "\n",
       "                                             clean_text  score  sentimen  \n",
       "0     my dream university mixed feeling pas selesai ...      1         1  \n",
       "1                          utbk gedung arsip cung teman      0         0  \n",
       "2                                cewek horor lihat temu     -3        -1  \n",
       "3                                 kantin rektorat malam      0         0  \n",
       "4         the most delicioso kebab in one and only gaza      1         1  \n",
       "...                                                 ...    ...       ...  \n",
       "4601                               bingung daftar dinas     -2        -1  \n",
       "4602                                               buka      0         0  \n",
       "4603                                               qris      0         0  \n",
       "4604                                                         0         0  \n",
       "4605                                         mowning ca      0         0  \n",
       "\n",
       "[4606 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_mapping = {\n",
    "    'negative': -1,\n",
    "    'neutral': 0,\n",
    "    'positive': 1\n",
    "}\n",
    "data['sentimen'] = data['sentimen'].map(sentiment_mapping)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import random\n",
    "\n",
    "# Assuming data is already loaded\n",
    "X = data['clean_text']\n",
    "y = data['sentimen']\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed, stratify=y)\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abad</th>\n",
       "      <th>abah</th>\n",
       "      <th>abal</th>\n",
       "      <th>abang</th>\n",
       "      <th>abaya</th>\n",
       "      <th>abdi</th>\n",
       "      <th>abiesst</th>\n",
       "      <th>abis</th>\n",
       "      <th>abisin</th>\n",
       "      <th>absen</th>\n",
       "      <th>...</th>\n",
       "      <th>yumcha</th>\n",
       "      <th>yutub</th>\n",
       "      <th>yuuk</th>\n",
       "      <th>zaenuri</th>\n",
       "      <th>zaki</th>\n",
       "      <th>zaman</th>\n",
       "      <th>zhafira</th>\n",
       "      <th>zodiak</th>\n",
       "      <th>zonk</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3224 rows Ã— 4903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abad  abah  abal  abang  abaya  abdi  abiesst  abis  abisin  absen  ...  \\\n",
       "0      0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "1      0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "2      0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "3      0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "4      0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "...    ...   ...   ...    ...    ...   ...      ...   ...     ...    ...  ...   \n",
       "3219   0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "3220   0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "3221   0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "3222   0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "3223   0.0   0.0   0.0    0.0    0.0   0.0      0.0   0.0     0.0    0.0  ...   \n",
       "\n",
       "      yumcha  yutub  yuuk  zaenuri  zaki  zaman  zhafira  zodiak  zonk  zoom  \n",
       "0        0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "1        0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "2        0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "3        0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "4        0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "...      ...    ...   ...      ...   ...    ...      ...     ...   ...   ...  \n",
       "3219     0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "3220     0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "3221     0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "3222     0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "3223     0.0    0.0   0.0      0.0   0.0    0.0      0.0     0.0   0.0   0.0  \n",
       "\n",
       "[3224 rows x 4903 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Menggunakan SMOTE\n",
    "smote = SMOTE(random_state=random_seed)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Kernel      C  Gamma  Coef0  Degree  Accuracy\n",
      "0    linear   0.01    NaN    NaN     NaN  0.662808\n",
      "1    linear   0.10    NaN    NaN     NaN  0.680897\n",
      "2    linear   1.00    NaN    NaN     NaN  0.799566\n",
      "3    linear   5.00    NaN    NaN     NaN  0.803907\n",
      "4    linear  10.00    NaN    NaN     NaN  0.802460\n",
      "5       rbf   0.01    1.0    NaN     NaN  0.672938\n",
      "6       rbf   0.10    1.0    NaN     NaN  0.694645\n",
      "7       rbf   1.00    1.0    NaN     NaN  0.794501\n",
      "8       rbf   5.00    1.0    NaN     NaN  0.809696\n",
      "9       rbf  10.00    1.0    NaN     NaN  0.809696\n",
      "10  sigmoid   0.01    1.0    0.0     NaN  0.651954\n",
      "11  sigmoid   0.10    1.0    0.0     NaN  0.680174\n",
      "12  sigmoid   1.00    1.0    0.0     NaN  0.797395\n",
      "13  sigmoid   5.00    1.0    0.0     NaN  0.783647\n",
      "14  sigmoid  10.00    1.0    0.0     NaN  0.769175\n",
      "15     poly   0.01    1.0    0.0     3.0  0.567294\n",
      "16     poly   0.10    1.0    0.0     3.0  0.556440\n",
      "17     poly   1.00    1.0    0.0     3.0  0.575253\n",
      "18     poly   5.00    1.0    0.0     3.0  0.573806\n",
      "19     poly  10.00    1.0    0.0     3.0  0.576700\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Parameter values\n",
    "C_values = [0.01, 0.1, 1,5, 10]\n",
    "gamma_values = [1]\n",
    "coef0_values = [0]\n",
    "degree_values = [3]\n",
    "\n",
    "# List to store results\n",
    "svm_results = []\n",
    "\n",
    "# Iterate over each kernel and parameter values\n",
    "for kernel in ['linear', 'rbf', 'sigmoid', 'poly']:\n",
    "    for C in C_values:\n",
    "        if kernel == 'linear':\n",
    "            # For linear kernel, only use parameter C\n",
    "            model = SVC(kernel=kernel, C=C, random_state=random_seed)\n",
    "            model.fit(X_train_smote, y_train_smote)\n",
    "            \n",
    "            # Predict with test data\n",
    "            y_pred = model.predict(X_test_tfidf)\n",
    "            \n",
    "            # Evaluate performance\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Save the result to the list\n",
    "            svm_results.append({\n",
    "                \"Kernel\": kernel,\n",
    "                \"C\": C,\n",
    "                \"Gamma\": None,\n",
    "                \"Coef0\": None,\n",
    "                \"Degree\": None,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "            \n",
    "        elif kernel == 'rbf':\n",
    "            # For RBF kernel, use C and gamma\n",
    "            for gamma in gamma_values:\n",
    "                model = SVC(kernel=kernel, C=C, gamma=gamma, random_state=random_seed)\n",
    "                model.fit(X_train_smote, y_train_smote)\n",
    "                \n",
    "                # Predict with test data\n",
    "                y_pred = model.predict(X_test_tfidf)\n",
    "                \n",
    "                # Evaluate performance\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                \n",
    "                # Save the result to the list\n",
    "                svm_results.append({\n",
    "                    \"Kernel\": kernel,\n",
    "                    \"C\": C,\n",
    "                    \"Gamma\": gamma,\n",
    "                    \"Coef0\": None,\n",
    "                    \"Degree\": None,\n",
    "                    \"Accuracy\": accuracy\n",
    "                })\n",
    "                \n",
    "        elif kernel == 'sigmoid':\n",
    "            # For sigmoid kernel, use C, gamma, and coef0\n",
    "            for gamma in gamma_values:\n",
    "                for coef0 in coef0_values:\n",
    "                    model = SVC(kernel=kernel, C=C, gamma=gamma, coef0=coef0, random_state=random_seed)\n",
    "                    model.fit(X_train_smote, y_train_smote)\n",
    "                    \n",
    "                    # Predict with test data\n",
    "                    y_pred = model.predict(X_test_tfidf)\n",
    "                    \n",
    "                    # Evaluate performance\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    # Save the result to the list\n",
    "                    svm_results.append({\n",
    "                        \"Kernel\": kernel,\n",
    "                        \"C\": C,\n",
    "                        \"Gamma\": gamma,\n",
    "                        \"Coef0\": coef0,\n",
    "                        \"Degree\": None,\n",
    "                        \"Accuracy\": accuracy\n",
    "                    })\n",
    "                    \n",
    "        elif kernel == 'poly':\n",
    "            # For polynomial kernel, use C, gamma, coef0, and degree\n",
    "            for gamma in gamma_values:\n",
    "                for coef0 in coef0_values:\n",
    "                    for degree in degree_values:\n",
    "                        model = SVC(kernel=kernel, C=C, gamma=gamma, coef0=coef0, degree=degree, random_state=random_seed)\n",
    "                        model.fit(X_train_smote, y_train_smote)\n",
    "                        \n",
    "                        # Predict with test data\n",
    "                        y_pred = model.predict(X_test_tfidf)\n",
    "                        \n",
    "                        # Evaluate performance\n",
    "                        accuracy = accuracy_score(y_test, y_pred)\n",
    "                        \n",
    "                        # Save the result to the list\n",
    "                        svm_results.append({\n",
    "                            \"Kernel\": kernel,\n",
    "                            \"C\": C,\n",
    "                            \"Gamma\": gamma,\n",
    "                            \"Coef0\": coef0,\n",
    "                            \"Degree\": degree,\n",
    "                            \"Accuracy\": accuracy\n",
    "                        })\n",
    "\n",
    "# Convert the list of results to a DataFrame for better visualization\n",
    "svm_results_df = pd.DataFrame(svm_results)\n",
    "\n",
    "# Display the table\n",
    "print(svm_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Kernel Linear ---\n",
      "Iteration 1 (params: 32.500505) - Accuracy: 0.805355\n",
      "Iteration 2 (params: 32.676989) - Accuracy: 0.805355\n",
      "Iteration 3 (params: 32.389603) - Accuracy: 0.805355\n",
      "Iteration 4 (params: 32.354560) - Accuracy: 0.805355\n",
      "Iteration 5 (params: 32.371554) - Accuracy: 0.805355\n",
      "Iteration 6 (params: 32.680309) - Accuracy: 0.805355\n",
      "Iteration 7 (params: 32.249845) - Accuracy: 0.805355\n",
      "Iteration 8 (params: 32.381061) - Accuracy: 0.805355\n",
      "Iteration 9 (params: 32.747239) - Accuracy: 0.805355\n",
      "Iteration 10 (params: 32.713263) - Accuracy: 0.805355\n",
      "\n",
      "Optimal parameters for linear kernel: [32.5005048]\n",
      "SVM PSO Final Accuracy for linear kernel: 0.8053545586107091\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Kernel Rbf ---\n",
      "Iteration 1 (params: 54.073861, 0.079281) - Accuracy: 0.819826\n",
      "Iteration 2 (params: 58.533809, 0.217933) - Accuracy: 0.816208\n",
      "Iteration 3 (params: 45.822254, 0.049342) - Accuracy: 0.816932\n",
      "Iteration 4 (params: 47.300388, 0.075449) - Accuracy: 0.819826\n",
      "Iteration 5 (params: 54.073892, 0.128359) - Accuracy: 0.819826\n",
      "Iteration 6 (params: 44.341531, 0.076660) - Accuracy: 0.819826\n",
      "Iteration 7 (params: 53.370900, 0.073920) - Accuracy: 0.820550\n",
      "Iteration 8 (params: 52.583665, 0.074883) - Accuracy: 0.820550\n",
      "Iteration 9 (params: 55.453081, 0.074636) - Accuracy: 0.819826\n",
      "Iteration 10 (params: 51.204289, 0.073810) - Accuracy: 0.820550\n",
      "\n",
      "Optimal parameters for rbf kernel: [53.37090029  0.07391995]\n",
      "SVM PSO Final Accuracy for rbf kernel: 0.8205499276410999\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Kernel Sigmoid ---\n",
      "Iteration 1 (params: 24.192405, 0.233568, -0.863627) - Accuracy: 0.805355\n",
      "Iteration 2 (params: 26.623551, 0.307039, -0.511046) - Accuracy: 0.803907\n",
      "Iteration 3 (params: 41.528277, 0.129115, -0.533615) - Accuracy: 0.806802\n",
      "Iteration 4 (params: 42.843462, 0.105159, -1.000000) - Accuracy: 0.806078\n",
      "Iteration 5 (params: 67.295816, 0.048657, -0.010196) - Accuracy: 0.807525\n",
      "Iteration 6 (params: 59.184237, 0.082787, -1.000000) - Accuracy: 0.808249\n",
      "Iteration 7 (params: 52.197595, 0.072476, -1.000000) - Accuracy: 0.805355\n",
      "Iteration 8 (params: 71.279737, 0.095971, -1.000000) - Accuracy: 0.809696\n",
      "Iteration 9 (params: 59.903435, 0.114394, -1.000000) - Accuracy: 0.808249\n",
      "Iteration 10 (params: 77.864762, 0.106288, -1.000000) - Accuracy: 0.807525\n",
      "\n",
      "Optimal parameters for sigmoid kernel: [71.27973679  0.09597143 -1.        ]\n",
      "SVM PSO Final Accuracy for sigmoid kernel: 0.8096960926193922\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Kernel Poly ---\n",
      "Iteration 1 (params: 60.771709, 0.088579, 0.353745, 2.192284) - Accuracy: 0.806802\n",
      "Iteration 2 (params: 17.224148, 0.181602, 1.000000, 3.023062) - Accuracy: 0.808249\n",
      "Iteration 3 (params: 29.427301, 0.056167, 0.622967, 2.707926) - Accuracy: 0.808249\n",
      "Iteration 4 (params: 15.336704, 0.067243, 1.000000, 2.979981) - Accuracy: 0.808249\n",
      "Iteration 5 (params: 11.174183, 0.085685, 1.000000, 3.060033) - Accuracy: 0.808249\n",
      "Iteration 6 (params: 14.584681, 0.067636, 1.000000, 2.506521) - Accuracy: 0.808249\n",
      "Iteration 7 (params: 33.350446, 0.070260, 1.000000, 2.724083) - Accuracy: 0.806078\n",
      "Iteration 8 (params: 22.009683, 0.363552, 1.000000, 2.813454) - Accuracy: 0.807525\n",
      "Iteration 9 (params: 20.926846, 0.155182, 1.000000, 3.003188) - Accuracy: 0.806802\n",
      "Iteration 10 (params: 11.996796, 0.124533, 1.000000, 2.976832) - Accuracy: 0.807525\n",
      "\n",
      "Optimal parameters for poly kernel: [17.22414766  0.18160205  1.          3.02306248]\n",
      "SVM PSO Final Accuracy for poly kernel: 0.8082489146164978\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fitness function\n",
    "def fitness_function(params, X_train, y_train, X_test, y_test, kernel):\n",
    "    # Adjust parameters based on the kernel\n",
    "    if kernel == 'linear':\n",
    "        C = params[0]\n",
    "        model = SVC(C=C, kernel=kernel, random_state=random_seed)\n",
    "\n",
    "    elif kernel == 'rbf':\n",
    "        C = params[0]\n",
    "        gamma = params[1]\n",
    "        model = SVC(C=C, gamma=gamma, kernel=kernel, random_state=random_seed)\n",
    "\n",
    "    elif kernel == 'sigmoid':\n",
    "        C = params[0]\n",
    "        gamma = params[1]\n",
    "        coef0 = params[2]\n",
    "        model = SVC(C=C, gamma=gamma, coef0=coef0, kernel=kernel, random_state=random_seed)\n",
    "\n",
    "    elif kernel == 'poly':\n",
    "        C = params[0]\n",
    "        gamma = params[1]\n",
    "        coef0 = params[2]\n",
    "        degree = int(params[3])  # Ensure degree is an integer\n",
    "        model = SVC(C=C, gamma=gamma, coef0=coef0, degree=degree, kernel=kernel, random_state=random_seed)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Particle class for PSO\n",
    "class Particle:\n",
    "    def __init__(self, bounds):\n",
    "        self.position = np.array([np.random.uniform(bound[0], bound[1]) for bound in bounds])\n",
    "        self.velocity = np.random.uniform(-1, 1, len(bounds))\n",
    "        self.best_position = self.position.copy()\n",
    "        self.best_score = -1\n",
    "\n",
    "# PSO optimization function with velocity update equation\n",
    "def pso_optimize(fitness_function, bounds, num_particles, X_train, y_train, X_test, y_test, kernel, num_iterations=10):\n",
    "    # Parameters for velocity update\n",
    "    w = 0.5  # Inertia weight\n",
    "    c1 = 2.0  # Cognitive learning coefficient\n",
    "    c2 = 2.0  # Social learning coefficient\n",
    "\n",
    "    particles = [Particle(bounds) for _ in range(num_particles)]\n",
    "    global_best_position = particles[0].position.copy()\n",
    "    global_best_score = -1\n",
    "\n",
    "    print(f\"--- Kernel {kernel.capitalize()} ---\")\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        iteration_best_score = -1\n",
    "        iteration_best_position = None\n",
    "        \n",
    "        for particle in particles:\n",
    "            # Evaluate the fitness of the particle's position\n",
    "            fitness = fitness_function(particle.position, X_train, y_train, X_test, y_test, kernel)\n",
    "\n",
    "            # Update the personal best if necessary\n",
    "            if fitness > particle.best_score:\n",
    "                particle.best_score = fitness\n",
    "                particle.best_position = particle.position.copy()\n",
    "\n",
    "            # Update the global best if necessary\n",
    "            if fitness > global_best_score:\n",
    "                global_best_score = fitness\n",
    "                global_best_position = particle.position.copy()\n",
    "\n",
    "            # Track the best fitness in this iteration\n",
    "            if fitness > iteration_best_score:\n",
    "                iteration_best_score = fitness\n",
    "                iteration_best_position = particle.position.copy()\n",
    "\n",
    "            # Random numbers r1 and r2\n",
    "            r1 = np.random.uniform(0, 1, len(bounds))\n",
    "            r2 = np.random.uniform(0, 1, len(bounds))\n",
    "\n",
    "            # Update velocity using PSO equation\n",
    "            particle.velocity = (\n",
    "                w * particle.velocity\n",
    "                + c1 * r1 * (particle.best_position - particle.position)\n",
    "                + c2 * r2 * (global_best_position - particle.position)\n",
    "            )\n",
    "\n",
    "            # Update the particle's position by adding velocity\n",
    "            particle.position += particle.velocity\n",
    "\n",
    "            # Ensure the position stays within bounds\n",
    "            for i in range(len(bounds)):\n",
    "                if particle.position[i] < bounds[i][0]:\n",
    "                    particle.position[i] = bounds[i][0]\n",
    "                if particle.position[i] > bounds[i][1]:\n",
    "                    particle.position[i] = bounds[i][1]\n",
    "\n",
    "        # Print the best fitness and parameters from this iteration\n",
    "        params_str = ', '.join([f\"{param:.6f}\" for param in iteration_best_position])\n",
    "        print(f\"Iteration {iteration + 1} (params: {params_str}) - Accuracy: {iteration_best_score:.6f}\")\n",
    "\n",
    "    return global_best_position, global_best_score\n",
    "\n",
    "\n",
    "# Kernels and parameter bounds\n",
    "kernels = ['linear', 'rbf', 'sigmoid', 'poly']\n",
    "bounds = {\n",
    "    'linear': [(0.1, 100)],  # Only C\n",
    "    'rbf': [(0.1, 100), (0.000001, 1)],  # C and gamma\n",
    "    'sigmoid': [(0.1, 100), (0.000001, 1), (-1,1)],  # C, gamma, and coef0\n",
    "    'poly': [(0.1, 100), (0.000001, 1), (-1,1), (2, 5)]  # C, gamma, coef0, and degree\n",
    "}\n",
    "\n",
    "# Iterate through each kernel\n",
    "for kernel in kernels:\n",
    "    bounds_for_kernel = bounds[kernel]\n",
    "\n",
    "    # PSO optimization with no iteration, only one evaluation for 10 particles\n",
    "    best_params, best_score = pso_optimize(fitness_function, bounds_for_kernel, num_particles=10, \n",
    "                                           X_train=X_train_smote, y_train=y_train_smote, \n",
    "                                           X_test=X_test_tfidf, y_test=y_test, \n",
    "                                           kernel=kernel)\n",
    "\n",
    "    print(f\"\\nOptimal parameters for {kernel} kernel: {best_params}\")\n",
    "\n",
    "    # Train SVM with optimal parameters\n",
    "    if kernel == 'poly':\n",
    "        # Poly kernel requires C, gamma, coef0, and degree\n",
    "        optimal_svm_clf = SVC(C=best_params[0], gamma=best_params[1], coef0=best_params[2], \n",
    "                            degree=int(best_params[3]), kernel=kernel, random_state=random_seed)\n",
    "    elif kernel == 'sigmoid':\n",
    "        # Sigmoid kernel requires C, gamma, and coef0\n",
    "        optimal_svm_clf = SVC(C=best_params[0], gamma=best_params[1], coef0=best_params[2], \n",
    "                            kernel=kernel, random_state=random_seed)\n",
    "    elif kernel == 'rbf':\n",
    "        # RBF kernel requires C and gamma\n",
    "        optimal_svm_clf = SVC(C=best_params[0], gamma=best_params[1], \n",
    "                            kernel=kernel, random_state=random_seed)\n",
    "    elif kernel == 'linear':\n",
    "        # Linear kernel only requires C\n",
    "        optimal_svm_clf = SVC(C=best_params[0], kernel=kernel, random_state=random_seed)\n",
    "\n",
    "    # Fit the model and predict\n",
    "    optimal_svm_clf.fit(X_train_smote, y_train_smote)\n",
    "    optimal_y_pred = optimal_svm_clf.predict(X_test_tfidf)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy_pso = accuracy_score(y_test, optimal_y_pred)\n",
    "    print(f\"SVM PSO Final Accuracy for {kernel} kernel: {accuracy_pso}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.12      0.20       299\n",
      "           0       0.55      0.98      0.71       711\n",
      "           1       0.82      0.18      0.29       372\n",
      "\n",
      "    accuracy                           0.58      1382\n",
      "   macro avg       0.71      0.42      0.40      1382\n",
      "weighted avg       0.67      0.58      0.49      1382\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.5767004341534009\n"
     ]
    }
   ],
   "source": [
    "#uji coba parameter\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "svm_model = SVC(kernel='poly', C=10, gamma=1, coef0=0, degree=3, random_state=random_seed)\n",
    "\n",
    "svm_model.fit(X_train_smote, y_train_smote)\n",
    "y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
